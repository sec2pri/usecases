---
title: "Secondary ChEBI IDs used in metabolomics databases"
output: html_notebook
author: 
- "DeniseSl22"
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

This script checks the occurance of outdated ChEBI IDs in metabolomics datasets in the Metabolights repository.

## 0. Notebook setup
The first section of this Notebook lists all the libraries required to run this script.

```{r}
#Package manager:
if(!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager",repos = "http://cran.us.r-project.org")
#Package for path variable
if(!"rstudioapi" %in% installed.packages()) BiocManager::install("rstudioapi")
#Libraries required for markdown documents:
if(!"markdown" %in% installed.packages()){install.packages("markdown")}
if(!"rmarkdown" %in% installed.packages()){install.packages("rmarkdown")}
#General libraries for data handling in R
if(!"dplyr" %in% installed.packages()){install.packages("dplyr")}
if(!"wget" %in% installed.packages()){install.packages("wget")}
#if(!"readxl" %in% installed.packages()){install.packages("readxl")}
#if(!"stringr" %in% installed.packages()){install.packages("stringr")}
#Libraries required for metabolighteR package:
#if(!"magrittr" %in% installed.packages()){install.packages("magrittr")}
#if(!"remotes" %in% installed.packages()){install.packages("remotes")}
# Install metabolighteR from GitHub if not installed
#if (!requireNamespace("metabolighteR", quietly = TRUE)) {
# remotes::install_github('aberHRML/metabolighteR')
#}
##Executing requests for APIs:
if(!"httr" %in% installed.packages()){install.packages("httr")}
##Reading JSON formatted data
if(!"jsonlite" %in% installed.packages()){install.packages("jsonlite")}
##Reading CSV/TSv data
if(!"readr" %in% installed.packages()){install.packages("readr")}

##Plotting data in Figures:
if(!"ggplot2" %in% installed.packages()){install.packages("ggplot2")}

#load libraries
library(rstudioapi)
library(dplyr)
library(tidyr)
library(wget)
#library(readxl)        # Load readxl package for reading Excel files
#library(stringr)        # To extract strings based on first complete match
#library(magrittr)
#library(remotes)         # Load remotes package for installing packages from GitHub
#library(metabolighteR)  # Load metabolighteR package for metabolite analysis
library(httr)           # To run APi calls
library(jsonlite)       # Handle JSON data from API calls
library(readr)          # Handle TSV data from Metabolights
library(ggplot2)

# set working environment to current folder
workingDirectory <- setwd(dirname(rstudioapi::getSourceEditorContext()$path))
```

## 1. ChEBI IDs download
First, we load all the primary and secondary IDs of ChEBI to be used in this comparison (based on data release in Github/Zenodo).
```{r, include=FALSE}
if(!file.exists("ChEBI_secID2priID.tsv")){
  download.file('https://github.com/sec2pri/mapping_preprocessing/raw/refs/heads/main/datasources/chebi/data/ChEBI_secID2priID.tsv', destfile=paste0(workingDirectory, '/ChEBI_secID2priID.tsv'), method = "wget", extra = "-r -p --random-wait") ##Replace with Zenodo download when available!
} ##wget gave error, manually added data for now!)
```


## 2. Metabolights data download
For each dataset in the Metabolights repository, we download the .MAF file, containing processed and annotated metabolites, extract the column with IDs, and add these to a dataframe to retain for later analysis.

### 2.0 Set location of Metabolights API
```{r}
##Metabolights API location:
BASE_URL <- "https://www.ebi.ac.uk:443/metabolights/ws/studies"
```

### 2.1 Get all study IDs currently available in Metabolights
```{r}

##Access study IDs
getStudies <- function() {
  studies <-
    httr::GET(BASE_URL) %>% httr::content('parsed')

  studyTibble <- dplyr::tibble(unlist(studies))
  names(studyTibble) <- 'study'

  return(studyTibble)
}

##Download all IDs of available studies.
allstudyIds <- getStudies()
##Convert response to a vector
vStudyIds <- as.vector(allstudyIds[[1]])
```

### 2.2 Get all .maf file names for available study IDs
```{r}

# Retrieve MAF file names per study ID
get_maf_files <- function(study_id) {
  # Construct URL for the specific study ID
  url <- paste0(BASE_URL, "/", study_id, "/files?include_raw_data=false")
  
  # Send GET request to retrieve data
  response <- GET(url)
  
  # Check if the request was successful
  if (status_code(response) == 200) {
    # Parse JSON content of the response
    files_info <- fromJSON(content(response, as = "text", encoding = "UTF-8"))
    # Extract study files information
    study_files <- files_info$study
    
    # Verify if study_files is a data frame
    if (!is.data.frame(study_files)) {
      stop("Expected study_files to be a data frame.")
    }
    
    # Filter for MAF files
    maf_files <- study_files$file[grepl("maf.tsv", study_files$file, ignore.case = TRUE)]
    
    # Check if MAF files were found
    if (length(maf_files) > 0) {
      return(maf_files)  # Return MAF file names
    } else {
      stop("MAF file not found in the study files list")
    }
  } else {
    stop("Failed to retrieve files list for study: ", study_id)
  }
}

# Function to process multiple study IDs and get their MAF file names
get_maf_filenames_for_studies <- function(study_ids) {
  # Initialize list to store MAF file names or error messages
  maf_file_names <- list()
  
  # Iterate over each study ID
  for (study_id in vStudyIds) {
    tryCatch({
      # Attempt to fetch MAF file names for current study ID
      maf_file_names[[study_id]] <- get_maf_files(study_id)
    }, error = function(e) {
      # Store error message if an error occurs
      maf_file_names[[study_id]] <- paste("Error:", e$message)
    })
  }
  
  return(maf_file_names)  # Return list of MAF file names or error messages
}

# Call the function to retrieve MAF file names for the study IDs
MAF_File_Names <- get_maf_filenames_for_studies(vStudyIds)

##Store results in file for later (if needed) --> Large List
saveRDS(MAF_File_Names, "allMAFfileNamesMetabolights.rds")

##Analyze which studies do not have a .maf file and could not be included in the analysis
namesVector <- names(MAF_File_Names)
##Compare against vector with all study IDs
difference <- setdiff(vStudyIds, namesVector)
length(difference)

##Analyze how many studies have no .maf file, and how many have 2 (or more files)
itemCounts <- (sapply(MAF_File_Names, length))
totalFilecount <- sum(itemCounts)
MoreThanOne_MAFfile <- sum(itemCounts > 1)

##Convert count data to see distribution numbers
counts <- table(itemCounts)
counts

##To visualise distribution:
dat <- as.data.frame(itemCounts)
mean_value <- mean(dat$itemCounts) 
mean_value
## Basic histogram from the vector "Freq". Each bin is .5 wide.
## These both result in the same output:
ggplot(dat, aes(x=itemCounts)) + geom_histogram(binwidth=.5)
# qplot(dat$rating, binwidth=.5)
```

### 2.3 Obtain content of .maf files per study ID
```{r}
# Check content of MAF file given a study ID and MAF file name
download_maf_files <- function(study_id, MAF_File_Names) {
  ##Create List to add ID data per dataset
df_list <- list()

    # Construct URL for downloading MAF file
    url <- paste0(BASE_URL, "/", study_id, "/download?file=", maf_filename)
    print(url)
    response <- GET(url) # Send GET request to download MAF file
    
    # Check if download was successful
    if (status_code(response) == 200) {
      response_content <- content(response, as = "text", encoding = "UTF-8")
      
      # Read tsv content 
      tsv_df <- read_tsv(response_content, show_col_types = FALSE, col_types = cols(.default = col_guess()))
      # Obtain ID mapping data
      idData <- na.omit(tsv_df$database_identifier) ##Removing rows without IDs
      filtered_vector <- idData[idData != "unknown"] ##Some data is labeled "unknown", also filter out
      
      ## Create a vector same length as IDs to combine results later.
      studyName <- rep(study_id, length(filtered_vector))
      
      # Create dataframe and add data
               tempDF <- data.frame(
               studyName = rep(study_id, length(filtered_vector)),
               IDs = filtered_vector,
               stringsAsFactors = FALSE
       )
      
      #Combine data from calls together; based on file name to avoid overwritting when 2 maf files exist per study.                  
      df_list[[maf_filename]] <- tempDF
      
    } else {
      stop("Failed to access MAF file: ", maf_filename, " for study: ", study_id)
    }
return(df_list)  
}

# Initialize master list
all_dfs <- list()

# Loop through each study ID and save the MAF files ID data
for (study_id in names(MAF_File_Names[1:16])) {
  
# Get MAF file names for current study ID
maf_filename <- MAF_File_Names[[study_id]]

 # Skip if there was an error retrieving MAF files
  if (length(maf_filename) == 1 && grepl("Error:", maf_files)) {
    cat(maf_filename, "\n")
    next # Skip to the next study ID
  }
# Download MAF files for current study ID
study_list <- download_maf_files(study_id, maf_filename)
# Append only if data was returned
  if (length(study_list) > 0) {
    all_dfs <- c(all_dfs, study_list)
  }
}

# Combine all results into one dataframe
finalDF <- do.call(rbind, all_dfs)
```


### 2.x Print all use package versions

```{r}
sessionInfo()
```


---
title: "Secondary ChEBI IDs used in metabolomics databases"
output: html_notebook
author: 
- "DeniseSl22"
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

This script checks the occurance of outdated ChEBI IDs in metabolomics datasets in the Metabolights repository.

## 0. Notebook setup
The first section of this Notebook lists all the libraries required to run this script.

```{r}
#Package manager:
if(!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager",repos = "http://cran.us.r-project.org")
#Package for path variable
if(!"rstudioapi" %in% installed.packages()) BiocManager::install("rstudioapi")
#Libraries required for markdown documents:
if(!"markdown" %in% installed.packages()){install.packages("markdown")}
if(!"rmarkdown" %in% installed.packages()){install.packages("rmarkdown")}
#General libraries for data handling in R
if(!"dplyr" %in% installed.packages()){install.packages("dplyr")}
if(!"wget" %in% installed.packages()){install.packages("wget")}
#if(!"readxl" %in% installed.packages()){install.packages("readxl")}
if(!"stringr" %in% installed.packages()){install.packages("stringr")}
#Libraries required for metabolighteR package:
#if(!"magrittr" %in% installed.packages()){install.packages("magrittr")}
#if(!"remotes" %in% installed.packages()){install.packages("remotes")}
# Install metabolighteR from GitHub if not installed
#if (!requireNamespace("metabolighteR", quietly = TRUE)) {
# remotes::install_github('aberHRML/metabolighteR')
#}
##Executing requests for APIs:
if(!"httr" %in% installed.packages()){install.packages("httr")}
##Reading JSON formatted data
if(!"jsonlite" %in% installed.packages()){install.packages("jsonlite")}
##Reading CSV/TSv data
if(!"readr" %in% installed.packages()){install.packages("readr")}

##Plotting data in Figures:
if(!"ggplot2" %in% installed.packages()){install.packages("ggplot2")}

#load libraries
library(rstudioapi)
library(dplyr)
library(tidyr)
library(wget)
#library(readxl)        # Load readxl package for reading Excel files
library(stringr)        # To extract strings based on first complete match
#library(magrittr)
#library(remotes)         # Load remotes package for installing packages from GitHub
#library(metabolighteR)  # Load metabolighteR package for metabolite analysis
library(httr)           # To run APi calls
library(jsonlite)       # Handle JSON data from API calls
library(readr)          # Handle TSV data from Metabolights
library(ggplot2)

# set working environment to current folder
workingDirectory <- setwd(dirname(rstudioapi::getSourceEditorContext()$path))
```

## 1. ChEBI IDs download
First, we load all the primary and secondary IDs of ChEBI to be used in this comparison (based on data release in Github/Zenodo).
```{r, include=FALSE}
if(!file.exists("ChEBI_secID2priID.tsv")){
  download.file('https://github.com/sec2pri/mapping_preprocessing/raw/refs/heads/main/datasources/chebi/data/ChEBI_secID2priID.tsv', destfile=paste0(workingDirectory, '/ChEBI_secID2priID.tsv'), method = "wget", extra = "-r -p --random-wait") ##Replace with Zenodo download when available!
} ##wget gave error, manually added data for now!)
```


## 2. Metabolights data download
For each dataset in the Metabolights repository, we download the .MAF file, containing processed and annotated metabolites, extract the column with IDs, and add these to a dataframe to retain for later analysis.

### 2.0 Set location of Metabolights API
```{r}
##Metabolights API location:
BASE_URL <- "https://www.ebi.ac.uk:443/metabolights/ws/studies"
```

### 2.1 Get all study IDs currently available in Metabolights
```{r}
##Access study IDs
getStudies <- function() {
  studies <-
    httr::GET(BASE_URL) %>% httr::content('parsed')

  studyTibble <- dplyr::tibble(unlist(studies))
  names(studyTibble) <- 'study'

  return(studyTibble)
}

##Download all IDs of available studies.
allstudyIds <- getStudies()
##Convert response to a vector
vStudyIds <- as.vector(allstudyIds[[1]])
```

### 2.2 Get all .maf file names for available study IDs
```{r}
# Retrieve MAF file names per study ID
get_maf_files <- function(study_id) {
  ##Add list to store output
  maf_files <- list ()
  
  # Construct URL for the specific study ID
  url <- paste0(BASE_URL, "/", study_id, "/files?include_raw_data=false")
  
  # Print message to console to keep track of status and potential errors.
    message("Requesting URL: ", url)
  # Pause between each URL call
    Sys.sleep(1)
  
  # Send GET request to retrieve data
    response <- GET(url)
  
  # Check if the request was successful
  if (status_code(response) == 200) {
    # Parse JSON content of the response
    files_info <- fromJSON(content(response, as = "text", encoding = "UTF-8"))
    # Extract study files information
    study_files <- files_info$study
    
    # Verify if study_files is a data frame
    if (!is.data.frame(study_files)) {
      stop("Expected study_files to be a data frame.")
    }
    
    # Filter for MAF files
    maf_files <- study_files$file[grepl("maf.tsv", study_files$file, ignore.case = TRUE)]
    
    # Check if MAF files were found
    if (length(maf_files) > 0) {
      return(maf_files)  # Return MAF file names
    } else {
      stop("MAF file not found in the study files list")
    }
  } else {
    stop("Failed to retrieve files list for study: ", study_id)
  }
}

# Function to process multiple study IDs and get their MAF file names
get_maf_filenames_for_studies <- function(study_ids) {
  # Initialize list to store MAF file names or error messages
  MAF_file_names <- list()
  
  # Iterate over each study ID
  for (study_id in vStudyIds) {
    tryCatch({
      # Attempt to fetch MAF file names for current study ID
      MAF_file_names[[study_id]] <- get_maf_files(study_id)
    }, error = function(e) {
      # Store error message if an error occurs
      MAF_file_names[[study_id]] <- paste("Error:", e$message)
    })
  }
  
  return(MAF_file_names)  # Return list of MAF file names or error messages
}

# Call the function to retrieve MAF file names for the study IDs
MAF_File_Names <- get_maf_filenames_for_studies(vStudyIds)

##Store results in file for later (if needed) --> Large List
saveRDS(MAF_File_Names, "allMAFfileNamesMetabolights.rds")

##Analyze which studies do not have a .maf file and could not be included in the analysis
namesVector <- names(MAF_File_Names)
##Compare against vector with all study IDs
difference <- setdiff(vStudyIds, namesVector)
length(difference)

##Analyze how many studies have no .maf file, and how many have 2 (or more files)
itemCounts <- (sapply(MAF_File_Names, length))
MoreThanOne_MAFfile <- sum(itemCounts > 1)

##Convert count data to see distribution numbers
counts <- table(itemCounts)
counts

##To visualise distribution:
dat <- as.data.frame(itemCounts)
mean_value <- mean(dat$itemCounts) 
mean_value
## Basic histogram from the vector "Freq". Each bin is .5 wide.
## These both result in the same output:
ggplot(dat, aes(x=itemCounts)) + geom_histogram(binwidth=.5)
# qplot(dat$rating, binwidth=.5)
```

### 2.3 Obtain content of .maf files per study ID
```{r}
# Check content of MAF file given a study ID and MAF file name
download_maf_files <- function(study_id, maf_filenames) {
  ## Create List to add ID data per dataset
  df_list_sanityCheck <- list()
  
  for (maf_filename in maf_filenames) {
    
    # Construct URL for downloading MAF file
    url <- paste0(BASE_URL, "/", study_id, "/download?file=", URLencode(maf_filename))
    
    # Print message to console to keep track of status and potential errors.
    message("Requesting URL: ", url)
    
    # Run the API call
    response <- GET(url)
    # Pause between each URL call
    Sys.sleep(1)
    
    if (status_code(response) == 200) {
      # Access content of .maf file
      response_content <- content(response, as = "text", encoding = "UTF-8")
      
      # Initialize filtered_vector
      filtered_vector <- c()
      
      if (!is.na(response_content)) {
        # Read tsv content
        tsv_df <- read_tsv(response_content, show_col_types = FALSE, col_types = cols(.default = col_guess()))
        # Obtain ID mapping data
        idData <- na.omit(tsv_df$database_identifier)
        filtered_vector <- idData[idData != "unknown"]
      } else {
        print(paste("Response data cannot be converted to tsv file for study:", study_id))
      }
      
      if (length(filtered_vector) > 0) {
        tempDF <- data.frame(
          studyName = rep(study_id, length(filtered_vector)),
          IDs = filtered_vector,
          stringsAsFactors = FALSE
        )
        
        # Combine data from calls together; based on file name
        df_list_sanityCheck[[maf_filename]] <- tempDF
      } else {
        message("No valid IDs found in file: ", maf_filename)
      }
      
    } else {
      warning("Failed to access MAF file: ", maf_filename, " for study: ", study_id)
    }
  }
  
  return(df_list_sanityCheck)
}

# Initialize master list
all_dfs_sanityCheck <- list()

# Loop through each study ID and save the MAF files ID data
##Running from last failed file (MTBLS1824, number 816) to debug/save time.
###Another fail (if (length(res) == 0 || res == -1) { :   missing value where TRUE/FALSE needed ) at MTBLS2914, number 1041. Resuming from next file again.
##Same error after MTBLS4273; number 1181; resuming from 1182.
###Different error, got stuck on study MTBLS5585, number 1289, resuming from 1290
##Same error after MTBLS6586; number 1346; resuming from 1347.
##Same error after MTBLS8920; number 1516; resuming from 1517
##Same error after MTBLS8954; number 1520; resuming from 1521
##Same error after MTBLS9087; number 1530; resuming from 1531
##Same error after MTBLS9522; number 1559; resuming from 1560
##Same error after MTBLS9662; number 1565; resuming from 1566
##Same error after MTBLS9665; number 1566; resuming from 1567 --> after adding waiting time of 5 sec. Perhaps latest studies do not all contain .maf file?
##Same error after MTBLS9795; number 1575; resuming from 1576 
##Same error after MTBLS10002; number 1598; resuming from 1599
##Same error after MTBLS10051; number 1602; resuming from 1603
for (study_id in names(MAF_File_Names)) {
  
# Get MAF file names for current study ID
maf_filename <- MAF_File_Names[[study_id]]

 # Skip if there was an error retrieving MAF files
  if (length(maf_filename) == 1 && grepl("Error:", maf_filename)) {
    cat(maf_filename, "\n")
    next # Skip to the next study ID
  }
# Download MAF files for current study ID
study_list <- download_maf_files(study_id, maf_filename)
# Append only if data was returned
  if (length(study_list) > 0) {
    all_dfs_sanityCheck <- c(all_dfs_sanityCheck, study_list)
  }
}

# Combine all results into one dataframe
finalDF_sanityCheck <- do.call(rbind, all_dfs_sanityCheck)
```


### 2.x Print all use package versions

```{r}
sessionInfo()
```

